{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7FyqLTqnEK55"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u9dH9j6XEK6I"
   },
   "outputs": [],
   "source": [
    "# !pip install flask-ngrok\n",
    "from flask_ngrok import run_with_ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "GeaJljsfRuc3",
    "outputId": "01a7e865-ae2f-4bfe-dab4-db4f1add14b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ashra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ashra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ashra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "model = keras.models.load_model(\"C:/Users/ashra/Documents/Enhance IT/NLP_group/\")\n",
    "\n",
    "    \n",
    "with open(\"C:/Users/ashra/Documents/Enhance IT/NLP_group/token.pickle\", \"rb\") as f:\n",
    "    \n",
    "    \n",
    "  token = dill.load(f)\n",
    "\n",
    "def normalizer(tweet):\n",
    "    no_urls = re.sub(r\"http\\S+\", \" \" ,tweet)\n",
    "    only_letters = re.sub(\"[^a-zA-Z]\", \" \",no_urls)\n",
    "    tokens = nltk.word_tokenize(only_letters)[2 :]\n",
    "    lower_case = [l.lower() for l in tokens]\n",
    "    filtered_result = list(filter(lambda l: l not in stop_words, lower_case))\n",
    "    #lemmas = [wordnet_lemmatizer.lemmatize(t) for t in filtered_result]\n",
    "    return filtered_result\n",
    "\n",
    "#make a prediction on input text\n",
    "def predict_on_text(text): \n",
    "  test_text = np.array([text])\n",
    "  test_df =  pd.DataFrame(test_text, columns = ['text'])\n",
    "\n",
    "  test_df['normalized_tweet'] = test_df.text.apply(normalizer)\n",
    "  X = test_df[\"normalized_tweet\"].astype(str)\n",
    "\n",
    "  df = token.texts_to_sequences(X)\n",
    "\n",
    "  print(df)\n",
    "\n",
    "  df = tf.keras.preprocessing.sequence.pad_sequences(df, maxlen=100)\n",
    "\n",
    "  print(df)\n",
    "\n",
    "  prediction = np.round(model.predict(df)[0][0]-.45)\n",
    "\n",
    "  if prediction:\n",
    "\n",
    "    return \"This is about Sports.\"\n",
    "\n",
    "  else:\n",
    "\n",
    "    return \"This is not about Sports.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RoX4iayMEK6Z"
   },
   "outputs": [],
   "source": [
    "app = Flask(__name__, template_folder= \"C:/Users/ashra/Documents/Enhance IT/NLP_group/Templates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lu5V9R26EK6p"
   },
   "outputs": [],
   "source": [
    "run_with_ngrok(app)   # Starts ngrok when the app is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iCk4qdhZEK60"
   },
   "outputs": [],
   "source": [
    "@app.route(\"/\",  methods=[\"POST\", \"GET\"])\n",
    "def home():\n",
    "\n",
    "    message = ''\n",
    "    if request.method == 'POST':\n",
    "        text = request.form.get('test_text')  # access the data inside \n",
    "        message = predict_on_text(text)\n",
    "    return render_template(\"home.html\", message = message)\n",
    "\n",
    "@app.route(\"/predict\",  methods=[\"POST\", \"GET\"])\n",
    "def chat():\n",
    "    return predict_on_text(request.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1D_7BoD6EK6_"
   },
   "outputs": [],
   "source": [
    "# app.run(host='0.0.0.0', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Zqyc34xaEK7K",
    "outputId": "eb06b271-7a61-47f4-c4fe-aba052b61f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [25/Oct/2020 18:50:08] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Running on http://993fd0f39238.ngrok.io\n",
      " * Traffic stats available on http://127.0.0.1:4040\n",
      "[[479, 463]]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0 479 463]]\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"embedding_input:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Oct/2020 18:50:15] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flask-Host.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
